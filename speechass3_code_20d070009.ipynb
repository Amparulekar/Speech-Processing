{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "69f32eda-5f55-44c1-a893-6f3c1ae55541",
      "metadata": {
        "id": "69f32eda-5f55-44c1-a893-6f3c1ae55541"
      },
      "source": [
        "METHOD DECRIPTION\n",
        "1. First step was endpointing, which is basically clipping the audio such that only the frames with energy above a threshold were retained. Thus, only the single words were included. Silence was clipped out.This was done to train and test files.\n",
        "2. Then preemphasis was added to remove noise.This was done to train and test files.\n",
        "3. Then 39 mfcc features were extracted from the train and test files.\n",
        "4. Then, the vq codebook matching method was carried out using kmeans clustering.\n",
        "5. K-means clustering is an iterative process of assigning each data point to the groups and slowly data points get clustered based on similar features. The objective is to minimize the sum of distances between the data points and the cluster centroid, to identify the correct group each data point should belong to.\n",
        "6. Using this, training and testing was done\n",
        "7. For noisy test files, training data was augmented with noise and the model was retrained on it and then tested on noisy data\n",
        "\n",
        "\n",
        "TESTING OBSERVATIONS AND RESULTS\n",
        "1. On increasing the number of clusters from 4 to 8 in K-means clustering, the accuracy improved from 31.2 to 39.5 percent on clean test data\n",
        "2. The k=4 models and k=8 models trained on clean data gave 25.54 and 29.9 accuracies on the noisy test data respectively so noise reduced prediction accuracy\n",
        "3. On augmentation of training data using noise, the k=4 models and k=8 models gave 20.2 and 23.9 accuracies on the noisy test data respectively so surprisingly noise augmentation reduced prediction accuracy on noisy data\n",
        "4. We can also observe from the confusion matrix that the best model performs the best on 'off' and worst on 'right', so short, more vowel-like words perform better than longer words which have consonants at their start and end.\n",
        "\n",
        "DISCUSSION\n",
        "\n",
        "Thus we can conclude that increasing k in kmeans clustering improved accuracy in this task. mfcc feature extraction is a good way for audio file characterization and classification, especially classification of short words. The accuracy of this method is low and i expect gmmhmm method to give better accuracy. Noise augmentation did not improve results on noisy test data, but it ideally should, this can be attributed to the type of adding noise or the way it was added."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e471961a-dfac-4f50-a4e5-e28c5c5e923c",
      "metadata": {
        "id": "e471961a-dfac-4f50-a4e5-e28c5c5e923c"
      },
      "source": [
        "CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f97e751-67c1-47dc-b832-587e8fe47774",
      "metadata": {
        "id": "8f97e751-67c1-47dc-b832-587e8fe47774"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import write\n",
        "from scipy.io import wavfile\n",
        "import scipy.signal as signal\n",
        "from IPython.display import Audio, display\n",
        "from scipy.fftpack import fft, dct\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.cluster.vq import vq, kmeans, whiten\n",
        "from hmmlearn import hmm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5672f84-ca98-475e-af31-c5724807400b",
      "metadata": {
        "id": "d5672f84-ca98-475e-af31-c5724807400b"
      },
      "source": [
        "ENDPOINTING - Taking out only the parts of speech with audio in it for training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df6f84e-1973-4898-8158-18cfcb413bbc",
      "metadata": {
        "id": "7df6f84e-1973-4898-8158-18cfcb413bbc"
      },
      "outputs": [],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"Commands Dataset-20200305T135856Z-001/Commands Dataset/train/\"+word)\n",
        "    for yesfile in trainyes:\n",
        "      read = wavfile.read('Commands Dataset-20200305T135856Z-001/Commands Dataset/train/'+word+'/'+ yesfile)\n",
        "      inp= read[1]\n",
        "      norminp = inp/max(abs(inp))\n",
        "      noofframes = len(norminp)//480\n",
        "      Senergy = []\n",
        "      for i in range(noofframes):\n",
        "            ham = np.zeros_like(norminp)\n",
        "            ham[480*i:(i+1)*480] = np.hamming(480)\n",
        "            Senergyind = sum((norminp**2)*(ham**2))\n",
        "            Senergy.append(Senergyind)\n",
        "      frame=5\n",
        "      while(frame<len(Senergy)):\n",
        "            if(Senergy[frame]>=0.5):\n",
        "                cut=inp[(frame-2)*480:(frame+18)*480]\n",
        "                write('./cut_trained/'+word+'/' + yesfile, 16000, cut)\n",
        "                frame+=27\n",
        "            else: frame+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915aaea5-f284-4c78-b1cd-5f2f6f6ff5a5",
      "metadata": {
        "id": "915aaea5-f284-4c78-b1cd-5f2f6f6ff5a5"
      },
      "outputs": [],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"Commands Dataset-20200305T135856Z-001/Commands Dataset/test_clean/\"+word)\n",
        "    for yesfile in trainyes:\n",
        "      read = wavfile.read('Commands Dataset-20200305T135856Z-001/Commands Dataset/test_clean/'+word+'/'+ yesfile)\n",
        "      inp= read[1]\n",
        "      norminp = inp/max(abs(inp))\n",
        "      noofframes = len(norminp)//480\n",
        "      Senergy = []\n",
        "      for i in range(noofframes):\n",
        "            ham = np.zeros_like(norminp)\n",
        "            ham[480*i:(i+1)*480] = np.hamming(480)\n",
        "            Senergyind = sum((norminp**2)*(ham**2))\n",
        "            Senergy.append(Senergyind)\n",
        "      frame=5\n",
        "      while(frame<len(Senergy)):\n",
        "            if(Senergy[frame]>=0.5):\n",
        "                cut=inp[(frame-2)*480:(frame+18)*480]\n",
        "                write('./cut_test_clean/'+word+'/' + yesfile, 16000, cut)\n",
        "                frame+=27\n",
        "            else: frame+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292a8b12-d1c3-492e-ad73-7c4fdbcb2184",
      "metadata": {
        "id": "292a8b12-d1c3-492e-ad73-7c4fdbcb2184"
      },
      "outputs": [],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"Commands Dataset-20200305T135856Z-001/Commands Dataset/test_noisy/\"+word)\n",
        "    for yesfile in trainyes:\n",
        "      read = wavfile.read('Commands Dataset-20200305T135856Z-001/Commands Dataset/test_noisy/'+word+'/'+ yesfile)\n",
        "      inp= read[1]\n",
        "      norminp = inp/max(abs(inp))\n",
        "      noofframes = len(norminp)//480\n",
        "      Senergy = []\n",
        "      for i in range(noofframes):\n",
        "            ham = np.zeros_like(norminp)\n",
        "            ham[480*i:(i+1)*480] = np.hamming(480)\n",
        "            Senergyind = sum((norminp**2)*(ham**2))\n",
        "            Senergy.append(Senergyind)\n",
        "      frame=5\n",
        "      while(frame<len(Senergy)):\n",
        "            if(Senergy[frame]>=0.5):\n",
        "                cut=inp[(frame-2)*480:(frame+18)*480]\n",
        "                write('./cut_test_noisy/'+word+'/' + yesfile, 16000, cut)\n",
        "                frame+=27\n",
        "            else: frame+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81339b0c-93d4-46a1-9b12-057f42836bcc",
      "metadata": {
        "id": "81339b0c-93d4-46a1-9b12-057f42836bcc"
      },
      "source": [
        "PREEMPHASIS addition in training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e1307d-0025-47a8-be7e-63356519ff30",
      "metadata": {
        "id": "d5e1307d-0025-47a8-be7e-63356519ff30"
      },
      "outputs": [],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"./cut_trained/\"+word)\n",
        "    for yesfile in trainyes:\n",
        "        read = wavfile.read('./cut_trained/'+word+'/'+ yesfile)\n",
        "        inp= read[1]\n",
        "        pe=np.zeros_like(inp)\n",
        "        for i in range(len(inp)):\n",
        "          if (i==0 or i==1):\n",
        "            pe[i]=inp[i]\n",
        "          else:\n",
        "            pe[i]=(inp[i]-0.95*inp[i-1])\n",
        "        write('./preemp/'+word+'/' + yesfile, 16000, pe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b465ecc8-0fe7-4def-acdf-6bfbdb6f90ad",
      "metadata": {
        "id": "b465ecc8-0fe7-4def-acdf-6bfbdb6f90ad"
      },
      "outputs": [],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"./cut_test_clean/\"+word)\n",
        "    for yesfile in trainyes:\n",
        "        read = wavfile.read('./cut_test_clean/'+word+'/'+ yesfile)\n",
        "        inp= read[1]\n",
        "        pe=np.zeros_like(inp)\n",
        "        for i in range(len(inp)):\n",
        "          if (i==0 or i==1):\n",
        "            pe[i]=inp[i]\n",
        "          else:\n",
        "            pe[i]=(inp[i]-0.95*inp[i-1])\n",
        "        write('./preemp_tc/'+word+'/' + yesfile, 16000, pe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bde10fa-1114-47cd-a632-e351f4d920c8",
      "metadata": {
        "id": "6bde10fa-1114-47cd-a632-e351f4d920c8"
      },
      "outputs": [],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"./cut_test_noisy/\"+word)\n",
        "    for yesfile in trainyes:\n",
        "        read = wavfile.read('./cut_test_noisy/'+word+'/'+ yesfile)\n",
        "        inp= read[1]\n",
        "        pe=np.zeros_like(inp)\n",
        "        for i in range(len(inp)):\n",
        "          if (i==0 or i==1):\n",
        "            pe[i]=inp[i]\n",
        "          else:\n",
        "            pe[i]=(inp[i]-0.95*inp[i-1])\n",
        "        write('./preemp_tn/'+word+'/' + yesfile, 16000, pe)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d518bea-9792-42ec-8047-d06f621dc6c8",
      "metadata": {
        "id": "8d518bea-9792-42ec-8047-d06f621dc6c8"
      },
      "source": [
        "EXTRACTING 39 MFCC features for training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f3b668-eb61-4ae6-8c04-91b808e516ab",
      "metadata": {
        "id": "92f3b668-eb61-4ae6-8c04-91b808e516ab"
      },
      "outputs": [],
      "source": [
        "def melbin(s, f, filters, fs):\n",
        "    bin=np.linspace(2595*np.log10(1 + (s/700)), 2595*np.log10(1 + (f/700)), filters+2)\n",
        "    for i in range(bin.shape[0]):\n",
        "        bin[i]=10**(bin[i]/2595)-1\n",
        "        bin[i]=np.floor((257)*bin[i]*700/16000)\n",
        "    return bin\n",
        "\n",
        "def melfil(f, filters):\n",
        "    fbank = np.zeros([filters,256+1])\n",
        "    for m in range(filters):\n",
        "        for k in range(int(f[m]), int(f[m+1])):\n",
        "            fbank[m,k] = (k - f[m]) / (f[m+1]-f[m])\n",
        "        for k in range(int(f[m+1]), int(f[m+2])):\n",
        "            fbank[m,k] = (f[m+2]-k) / (f[m+2]-f[m+1])\n",
        "    return fbank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce729a5e-ab0e-4eef-8f1b-b6c33237ca59",
      "metadata": {
        "id": "ce729a5e-ab0e-4eef-8f1b-b6c33237ca59",
        "outputId": "a76e7936-927a-4dff-8e52-b3ab33e56c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extractedtrainingfeatureforlabel 1\n",
            "extractedtrainingfeatureforlabel 2\n",
            "extractedtrainingfeatureforlabel 3\n",
            "extractedtrainingfeatureforlabel 4\n",
            "extractedtrainingfeatureforlabel 5\n",
            "extractedtrainingfeatureforlabel 6\n",
            "extractedtrainingfeatureforlabel 7\n",
            "extractedtrainingfeatureforlabel 8\n",
            "extractedtrainingfeatureforlabel 9\n",
            "extractedtrainingfeatureforlabel 10\n"
          ]
        }
      ],
      "source": [
        "filters=26\n",
        "traincodebook= np.zeros((10,2350*60,39))\n",
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "i=0\n",
        "for word in words:\n",
        "    j=0\n",
        "    for file in os.listdir('./preemp/'+word):\n",
        "        read = wavfile.read('./preemp/'+word+'/'+file)\n",
        "        inp=read[1]\n",
        "        if (len(inp)<9600):\n",
        "            inp=np.append(inp,np.zeros(9600-len(inp)))\n",
        "        norminp = inp/max(abs(inp))\n",
        "        nFrames = len(norminp)//160\n",
        "        feat=[]\n",
        "        for k in range(nFrames):\n",
        "            frame = norminp[k*160:(k+1)*160]*np.hamming(160)\n",
        "            p=(np.abs(np.fft.fft(frame, n=512))**2)/frame.shape[0]\n",
        "            bins = melbin(300, 4000, filters, 16000)\n",
        "            fbank = melfil(bins, filters)\n",
        "            c=np.dot(p[:257],fbank.T)\n",
        "            if (0.0 in c):\n",
        "                c[c == 0.0] = 0.000001\n",
        "            c=dct(20*np.log10(c))\n",
        "            feat.append(c[:13])\n",
        "        mfcc13 = np.array(feat)\n",
        "        mfcc39 = np.zeros((mfcc13.shape[0], 39))\n",
        "        mfcc39[:,:13] = mfcc13\n",
        "        mfcc39[:,13:26] = mfcc13\n",
        "        mfcc39[:,26:39] = mfcc13\n",
        "        for l in range(1,12):\n",
        "            mfcc39[:,13+l] = (mfcc13[:,l+1] - mfcc13[:,l-1])/2.0\n",
        "        for l in range(2,11):\n",
        "            mfcc39[:,26+l] = (mfcc13[:,l+2] - mfcc13[:,l-2])/2.0\n",
        "        traincodebook[i,j*60:(j+1)*60,:] = mfcc39\n",
        "        j=j+1\n",
        "    i=i+1\n",
        "    print('extractedtrainingfeatureforlabel', i)\n",
        "np.save('codebook',traincodebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed1a253-4309-414f-9a6c-1a5e434ea6f0",
      "metadata": {
        "id": "fed1a253-4309-414f-9a6c-1a5e434ea6f0",
        "outputId": "d606c980-02c3-4c5e-f1b3-495008f5e22b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 141000, 39)\n"
          ]
        }
      ],
      "source": [
        "print(traincodebook.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047787e8-fc0a-45d1-a060-650c8fb47e9e",
      "metadata": {
        "id": "047787e8-fc0a-45d1-a060-650c8fb47e9e"
      },
      "source": [
        "TRAINING VQ codebook using K-means clustering for k=4 and 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0cabdb6-2c3c-49f1-9eba-cc7ca3e65a1f",
      "metadata": {
        "id": "c0cabdb6-2c3c-49f1-9eba-cc7ca3e65a1f",
        "outputId": "db3aaacb-43e9-4c43-819f-6280652b2d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "traininglabel 0\n",
            "traininglabel 1\n",
            "traininglabel 2\n",
            "traininglabel 3\n",
            "traininglabel 4\n",
            "traininglabel 5\n",
            "traininglabel 6\n",
            "traininglabel 7\n",
            "traininglabel 8\n",
            "traininglabel 9\n"
          ]
        }
      ],
      "source": [
        "vqcodebook4=np.zeros((10,4,39))\n",
        "for i in range(10):\n",
        "    vqcodebook4[i] = kmeans(traincodebook[i],4)[0]\n",
        "    print('traininglabel',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a60586f8-a104-473d-a83b-4bd8062051a6",
      "metadata": {
        "id": "a60586f8-a104-473d-a83b-4bd8062051a6",
        "outputId": "1b23f8d7-a60e-4420-d525-adcd0d011793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "traininglabel 0\n",
            "traininglabel 1\n",
            "traininglabel 2\n",
            "traininglabel 3\n",
            "traininglabel 4\n",
            "traininglabel 5\n",
            "traininglabel 6\n",
            "traininglabel 7\n",
            "traininglabel 8\n",
            "traininglabel 9\n"
          ]
        }
      ],
      "source": [
        "vqcodebook8=np.zeros((10,8,39))\n",
        "for i in range(10):\n",
        "    vqcodebook8[i] = kmeans(traincodebook[i],8)[0]\n",
        "    print('traininglabel',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deab2402-7a84-4ff1-a028-3a6dc22a7ad3",
      "metadata": {
        "id": "deab2402-7a84-4ff1-a028-3a6dc22a7ad3",
        "outputId": "298830c3-eb0f-40f5-b85a-3ff72adaa1d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 4, 39)\n",
            "(10, 8, 39)\n"
          ]
        }
      ],
      "source": [
        "np.save('model4',vqcodebook4)\n",
        "np.save('model8',vqcodebook8)\n",
        "print(vqcodebook4.shape)\n",
        "print(vqcodebook8.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae0a72b-e7af-4355-9e5d-97361e9c8370",
      "metadata": {
        "id": "0ae0a72b-e7af-4355-9e5d-97361e9c8370"
      },
      "source": [
        "EXTRACTING 39 MFCC features for clean testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef16ee7-d977-4fb8-aefc-7c6af5f81071",
      "metadata": {
        "id": "6ef16ee7-d977-4fb8-aefc-7c6af5f81071",
        "outputId": "fe42807a-4808-4c79-e748-4f8b10a340a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extractedcleantestfeatureforlabel 1\n",
            "extractedcleantestfeatureforlabel 2\n",
            "extractedcleantestfeatureforlabel 3\n",
            "extractedcleantestfeatureforlabel 4\n",
            "extractedcleantestfeatureforlabel 5\n",
            "extractedcleantestfeatureforlabel 6\n",
            "extractedcleantestfeatureforlabel 7\n",
            "extractedcleantestfeatureforlabel 8\n",
            "extractedcleantestfeatureforlabel 9\n",
            "extractedcleantestfeatureforlabel 10\n"
          ]
        }
      ],
      "source": [
        "filters=26\n",
        "testccodebook= np.zeros((10,240*60,39))\n",
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "i=0\n",
        "for word in words:\n",
        "    j=0\n",
        "    for file in os.listdir('./preemp_tc/'+word):\n",
        "        read = wavfile.read('./preemp_tc/'+word+'/'+file)\n",
        "        inp=read[1]\n",
        "        if (len(inp)<9600):\n",
        "            inp=np.append(inp,np.zeros(9600-len(inp)))\n",
        "        norminp = inp/max(abs(inp))\n",
        "        nFrames = len(norminp)//160\n",
        "        feat=[]\n",
        "        for k in range(nFrames):\n",
        "            frame = norminp[k*160:(k+1)*160]*np.hamming(160)\n",
        "            p=(np.abs(np.fft.fft(frame, n=512))**2)/frame.shape[0]\n",
        "            bins = melbin(300, 4000, filters, 16000)\n",
        "            fbank = melfil(bins, filters)\n",
        "            c=np.dot(p[:257],fbank.T)\n",
        "            if (0.0 in c):\n",
        "                c[c == 0.0] = 0.000001\n",
        "            c=dct(20*np.log10(c))\n",
        "            feat.append(c[:13])\n",
        "        mfcc13 = np.array(feat)\n",
        "        mfcc39 = np.zeros((mfcc13.shape[0], 39))\n",
        "        mfcc39[:,:13] = mfcc13\n",
        "        mfcc39[:,13:26] = mfcc13\n",
        "        mfcc39[:,26:39] = mfcc13\n",
        "        for l in range(1,12):\n",
        "            mfcc39[:,13+l] = (mfcc13[:,l+1] - mfcc13[:,l-1])/2.0\n",
        "        for l in range(2,11):\n",
        "            mfcc39[:,26+l] = (mfcc13[:,l+2] - mfcc13[:,l-2])/2.0\n",
        "        testccodebook[i,j*60:(j+1)*60,:] = mfcc39\n",
        "        j=j+1\n",
        "    i=i+1\n",
        "    print('extractedcleantestfeatureforlabel', i)\n",
        "np.save('testccodebook',testccodebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0e0824-5474-4334-9943-dd4e823010f7",
      "metadata": {
        "id": "ed0e0824-5474-4334-9943-dd4e823010f7",
        "outputId": "d0a141b3-0fe4-44cc-9efd-2f0004578af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 16800, 39)\n"
          ]
        }
      ],
      "source": [
        "print(testccodebook.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9653826-4b74-4171-9634-2054c5996029",
      "metadata": {
        "id": "c9653826-4b74-4171-9634-2054c5996029"
      },
      "source": [
        "TESTING on clean test data to get accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90dba7e4-cc1b-4907-af9a-0f7aa40f87b4",
      "metadata": {
        "id": "90dba7e4-cc1b-4907-af9a-0f7aa40f87b4",
        "outputId": "6e96196e-3452-452f-cc57-f401d044024e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing on label 0\n",
            "testing on label 1\n",
            "testing on label 2\n",
            "testing on label 3\n",
            "testing on label 4\n",
            "testing on label 5\n",
            "testing on label 6\n",
            "testing on label 7\n",
            "testing on label 8\n",
            "testing on label 9\n",
            "Accuracy= 31.208333333333332\n",
            "[[ 85  11   6  36   7   4  27   3  31  30]\n",
            " [ 13  74  13  12  10   5  59   6  25  23]\n",
            " [ 29   7  66  11  14  12  48   3  26  24]\n",
            " [ 50   6   2  48  17  15  23  11  30  38]\n",
            " [ 36  16  12  22  33   7  52   3  32  27]\n",
            " [  8  23  11  11   5  85  46  11  28  12]\n",
            " [ 30  33  16  13   8   4  99   1  21  15]\n",
            " [  7   2   4   4   1   9   7 147  33  26]\n",
            " [  7  10   5   8   5  13  13  69  51  59]\n",
            " [ 14  12   4  21   4  16   8  54  46  61]]\n"
          ]
        }
      ],
      "source": [
        "pred= []\n",
        "gt= []\n",
        "for i in range(10):\n",
        "    for j in range(240):\n",
        "        feat = testccodebook[i, 60*j:60*(j+1),:]\n",
        "        labeldist=[]\n",
        "        for label in range(10):\n",
        "            sumdist=0\n",
        "            for l in range (60):\n",
        "                dists=[]\n",
        "                for k in range(4):\n",
        "                    dist=0.0\n",
        "                    for m in range(39):\n",
        "                        dist=dist+ (feat[l][m]-vqcodebook4[label,k][m])**2\n",
        "                    dists.append(dist)\n",
        "                sumdist= sumdist+  min(dists)\n",
        "            labeldist.append(sumdist)\n",
        "        prediction=np.argmin(labeldist)\n",
        "        pred.append(prediction)\n",
        "        gt.append(i)\n",
        "    print('testing on label',i)\n",
        "true=0\n",
        "for q in range (len(gt)):\n",
        "    if (gt[q]==pred[q]):\n",
        "        true=true+1\n",
        "print(\"Accuracy=\",true*100/len(gt))\n",
        "print(confusion_matrix(gt, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e112d7-680b-40a1-87ea-fea5de376c2c",
      "metadata": {
        "id": "31e112d7-680b-40a1-87ea-fea5de376c2c",
        "outputId": "65615f9d-3d73-4899-c8d8-cae7828cd3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing on label 0\n",
            "testing on label 1\n",
            "testing on label 2\n",
            "testing on label 3\n",
            "testing on label 4\n",
            "testing on label 5\n",
            "testing on label 6\n",
            "testing on label 7\n",
            "testing on label 8\n",
            "testing on label 9\n",
            "Accuracy= 39.541666666666664\n",
            "[[108  10   7  45  13   4  22   5  13  13]\n",
            " [  4  91  12  14  16  10  55   4  18  16]\n",
            " [  1   4  89  18  21  18  50   4  13  22]\n",
            " [ 35  13   8  72  29  10  15   7  13  38]\n",
            " [ 21  19  21  37  59   6  44   2   9  22]\n",
            " [  2  21  26   9   2  89  41  11  12  27]\n",
            " [  9  24  21  14   8   9 130   2   8  15]\n",
            " [  1   5   3   2   0  16   3 150  22  38]\n",
            " [  2  15   6  15   6  12   5  44  60  75]\n",
            " [  0  25   4  15   6  11   5  32  41 101]]\n"
          ]
        }
      ],
      "source": [
        "pred= []\n",
        "gt= []\n",
        "for i in range(10):\n",
        "    for j in range(240):\n",
        "        feat = testccodebook[i, 60*j:60*(j+1),:]\n",
        "        labeldist=[]\n",
        "        for label in range(10):\n",
        "            sumdist=0\n",
        "            for l in range (60):\n",
        "                dists=[]\n",
        "                for k in range(8):\n",
        "                    dist=0.0\n",
        "                    for m in range(39):\n",
        "                        dist=dist+ (feat[l][m]-vqcodebook8[label,k][m])**2\n",
        "                    dists.append(dist)\n",
        "                sumdist= sumdist+  min(dists)\n",
        "            labeldist.append(sumdist)\n",
        "        prediction=np.argmin(labeldist)\n",
        "        pred.append(prediction)\n",
        "        gt.append(i)\n",
        "    print('testing on label',i)\n",
        "true=0\n",
        "for q in range (len(gt)):\n",
        "    if (gt[q]==pred[q]):\n",
        "        true=true+1\n",
        "print(\"Accuracy=\",true*100/len(gt))\n",
        "print(confusion_matrix(gt, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0203e4c6-7f8e-4bf1-b3f4-51307193ea05",
      "metadata": {
        "id": "0203e4c6-7f8e-4bf1-b3f4-51307193ea05"
      },
      "source": [
        "TESTING on noisy test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2642e75c-d814-45ba-a2ad-ec1565b8c744",
      "metadata": {
        "id": "2642e75c-d814-45ba-a2ad-ec1565b8c744",
        "outputId": "382e2724-3982-4860-cf6a-69673d275132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extractedcleantestfeatureforlabel 1\n",
            "extractedcleantestfeatureforlabel 2\n",
            "extractedcleantestfeatureforlabel 3\n",
            "extractedcleantestfeatureforlabel 4\n",
            "extractedcleantestfeatureforlabel 5\n",
            "extractedcleantestfeatureforlabel 6\n",
            "extractedcleantestfeatureforlabel 7\n",
            "extractedcleantestfeatureforlabel 8\n",
            "extractedcleantestfeatureforlabel 9\n",
            "extractedcleantestfeatureforlabel 10\n"
          ]
        }
      ],
      "source": [
        "filters=26\n",
        "testncodebook= np.zeros((10,240*60,39))\n",
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "i=0\n",
        "for word in words:\n",
        "    j=0\n",
        "    for file in os.listdir('./preemp_tn/'+word):\n",
        "        read = wavfile.read('./preemp_tn/'+word+'/'+file)\n",
        "        inp=read[1]\n",
        "        if (len(inp)<9600):\n",
        "            inp=np.append(inp,np.zeros(9600-len(inp)))\n",
        "        norminp = inp/max(abs(inp))\n",
        "        nFrames = len(norminp)//160\n",
        "        feat=[]\n",
        "        for k in range(nFrames):\n",
        "            frame = norminp[k*160:(k+1)*160]*np.hamming(160)\n",
        "            p=(np.abs(np.fft.fft(frame, n=512))**2)/frame.shape[0]\n",
        "            bins = melbin(300, 4000, filters, 16000)\n",
        "            fbank = melfil(bins, filters)\n",
        "            c=np.dot(p[:257],fbank.T)\n",
        "            if (0.0 in c):\n",
        "                c[c == 0.0] = 0.000001\n",
        "            c=dct(20*np.log10(c))\n",
        "            feat.append(c[:13])\n",
        "        mfcc13 = np.array(feat)\n",
        "        mfcc39 = np.zeros((mfcc13.shape[0], 39))\n",
        "        mfcc39[:,:13] = mfcc13\n",
        "        mfcc39[:,13:26] = mfcc13\n",
        "        mfcc39[:,26:39] = mfcc13\n",
        "        for l in range(1,12):\n",
        "            mfcc39[:,13+l] = (mfcc13[:,l+1] - mfcc13[:,l-1])/2.0\n",
        "        for l in range(2,11):\n",
        "            mfcc39[:,26+l] = (mfcc13[:,l+2] - mfcc13[:,l-2])/2.0\n",
        "        testncodebook[i,j*60:(j+1)*60,:] = mfcc39\n",
        "        j=j+1\n",
        "    i=i+1\n",
        "    print('extractedcleantestfeatureforlabel', i)\n",
        "np.save('testncodebook',testncodebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495f5243-9855-48b4-bd9d-fe2aae9613c5",
      "metadata": {
        "id": "495f5243-9855-48b4-bd9d-fe2aae9613c5",
        "outputId": "11a33c58-c76f-4451-e58f-239ab2ed3201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing on label 0\n",
            "testing on label 1\n",
            "testing on label 2\n",
            "testing on label 3\n",
            "testing on label 4\n",
            "testing on label 5\n",
            "testing on label 6\n",
            "testing on label 7\n",
            "testing on label 8\n",
            "testing on label 9\n",
            "Accuracy= 25.541666666666668\n",
            "[[ 60   5  18  37   7   8  14  30  25  36]\n",
            " [  8  50  22  19   5  19  40  27  24  26]\n",
            " [ 29   4  59  34   7  18  25  17  27  20]\n",
            " [ 40   4  10  42  14  16  12  39  28  35]\n",
            " [ 29   9  22  43  17  15  34  15  27  29]\n",
            " [  6  11  19  10   4  74  25  39  34  18]\n",
            " [ 32  19  30  32   4  15  54  14  20  20]\n",
            " [  4   2   7   2   2  16   6 146  26  29]\n",
            " [  5   2   7   8   1   9   5  91  46  66]\n",
            " [ 11   4   7   9   2  14   3  83  42  65]]\n"
          ]
        }
      ],
      "source": [
        "pred= []\n",
        "gt= []\n",
        "for i in range(10):\n",
        "    for j in range(240):\n",
        "        feat = testncodebook[i, 60*j:60*(j+1),:]\n",
        "        labeldist=[]\n",
        "        for label in range(10):\n",
        "            sumdist=0\n",
        "            for l in range (60):\n",
        "                dists=[]\n",
        "                for k in range(4):\n",
        "                    dist=0.0\n",
        "                    for m in range(39):\n",
        "                        dist=dist+ (feat[l][m]-vqcodebook4[label,k][m])**2\n",
        "                    dists.append(dist)\n",
        "                sumdist= sumdist+  min(dists)\n",
        "            labeldist.append(sumdist)\n",
        "        prediction=np.argmin(labeldist)\n",
        "        pred.append(prediction)\n",
        "        gt.append(i)\n",
        "    print('testing on label',i)\n",
        "true=0\n",
        "for q in range (len(gt)):\n",
        "    if (gt[q]==pred[q]):\n",
        "        true=true+1\n",
        "print(\"Accuracy=\",true*100/len(gt))\n",
        "print(confusion_matrix(gt, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da4dff5-7258-48b2-b379-93e7e524759c",
      "metadata": {
        "id": "1da4dff5-7258-48b2-b379-93e7e524759c",
        "outputId": "e8c63bc3-aac3-4868-9d8d-86e1e24f1bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing on label 0\n",
            "testing on label 1\n",
            "testing on label 2\n",
            "testing on label 3\n",
            "testing on label 4\n",
            "testing on label 5\n",
            "testing on label 6\n",
            "testing on label 7\n",
            "testing on label 8\n",
            "testing on label 9\n",
            "Accuracy= 29.916666666666668\n",
            "[[ 73   4  13  66   5   6  13  34  16  10]\n",
            " [  7  56  32  25   9  11  34  36  20  10]\n",
            " [  3   2  75  49  10  21  22  19  10  29]\n",
            " [ 26   9  12  71  19  10   7  46  18  22]\n",
            " [ 14  13  19  77  35   4  26  12  18  22]\n",
            " [  1  10  36  12   2  64  21  51  18  25]\n",
            " [  8  14  38  44   8  13  68  14  18  15]\n",
            " [  1   2  11   0   0   8   2 161  20  35]\n",
            " [  1   3   7  16   6   5   2  88  51  61]\n",
            " [  1  11   8  14   3   7   4 100  28  64]]\n"
          ]
        }
      ],
      "source": [
        "pred= []\n",
        "gt= []\n",
        "for i in range(10):\n",
        "    for j in range(240):\n",
        "        feat = testncodebook[i, 60*j:60*(j+1),:]\n",
        "        labeldist=[]\n",
        "        for label in range(10):\n",
        "            sumdist=0\n",
        "            for l in range (60):\n",
        "                dists=[]\n",
        "                for k in range(8):\n",
        "                    dist=0.0\n",
        "                    for m in range(39):\n",
        "                        dist=dist+ (feat[l][m]-vqcodebook8[label,k][m])**2\n",
        "                    dists.append(dist)\n",
        "                sumdist= sumdist+  min(dists)\n",
        "            labeldist.append(sumdist)\n",
        "        prediction=np.argmin(labeldist)\n",
        "        pred.append(prediction)\n",
        "        gt.append(i)\n",
        "    print('testing on label',i)\n",
        "true=0\n",
        "for q in range (len(gt)):\n",
        "    if (gt[q]==pred[q]):\n",
        "        true=true+1\n",
        "print(\"Accuracy=\",true*100/len(gt))\n",
        "print(confusion_matrix(gt, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b12fcf73-ff44-44cb-9a28-742d15ac904c",
      "metadata": {
        "id": "b12fcf73-ff44-44cb-9a28-742d15ac904c"
      },
      "source": [
        "ADDING NOISE augmentations to clean training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78781a78-3319-43e5-830e-ca7135a8cff0",
      "metadata": {
        "id": "78781a78-3319-43e5-830e-ca7135a8cff0",
        "outputId": "f9fc2b78-dbda-4552-d608-03933be77035"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/amruta/code/add_noise.py:17: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  sampFreq, noise = wavfile.read(noisefile)\n"
          ]
        }
      ],
      "source": [
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "noise=['doing_the_dishes.wav','dude_miaowing.wav','exercise_bike.wav','pink_noise.wav','running_tap.wav','white_noise.wav']\n",
        "from add_noise import *\n",
        "for word in words:\n",
        "    trainyes=os.listdir(\"./preemp/\"+word)\n",
        "    for file in trainyes:\n",
        "        add_noise(\"./preemp/\"+word+\"/\"+file,\n",
        "                  \"Commands Dataset-20200305T135856Z-001/Commands Dataset/_background_noise_/\"+ np.random.choice(noise),\n",
        "                  \"./preemp_noise/\"+word+\"/\"+file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "676372e0-9bc9-44cc-a503-ce5f6c4a5ab6",
      "metadata": {
        "id": "676372e0-9bc9-44cc-a503-ce5f6c4a5ab6"
      },
      "source": [
        "TRAINING on augmented noisy data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b56f91-1608-4e43-9f2b-dec042aee0f0",
      "metadata": {
        "id": "40b56f91-1608-4e43-9f2b-dec042aee0f0",
        "outputId": "0750576d-8392-412a-bfb3-ed9b0696df99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extractedtrainingfeatureforlabel 1\n",
            "extractedtrainingfeatureforlabel 2\n",
            "extractedtrainingfeatureforlabel 3\n",
            "extractedtrainingfeatureforlabel 4\n",
            "extractedtrainingfeatureforlabel 5\n",
            "extractedtrainingfeatureforlabel 6\n",
            "extractedtrainingfeatureforlabel 7\n",
            "extractedtrainingfeatureforlabel 8\n",
            "extractedtrainingfeatureforlabel 9\n",
            "extractedtrainingfeatureforlabel 10\n"
          ]
        }
      ],
      "source": [
        "filters=26\n",
        "trainncodebook= np.zeros((10,2350*60,39))\n",
        "words=['yes','go','down','left','right','on','no','off','up','stop']\n",
        "i=0\n",
        "for word in words:\n",
        "    j=0\n",
        "    for file in os.listdir('./preemp_noise/'+word):\n",
        "        read = wavfile.read('./preemp_noise/'+word+'/'+file)\n",
        "        inp=read[1]\n",
        "        if (len(inp)<9600):\n",
        "            inp=np.append(inp,np.zeros(9600-len(inp)))\n",
        "        norminp = inp/max(abs(inp))\n",
        "        nFrames = len(norminp)//160\n",
        "        feat=[]\n",
        "        for k in range(nFrames):\n",
        "            frame = norminp[k*160:(k+1)*160]*np.hamming(160)\n",
        "            p=(np.abs(np.fft.fft(frame, n=512))**2)/frame.shape[0]\n",
        "            bins = melbin(300, 4000, filters, 16000)\n",
        "            fbank = melfil(bins, filters)\n",
        "            c=np.dot(p[:257],fbank.T)\n",
        "            if (0.0 in c):\n",
        "                c[c == 0.0] = 0.000001\n",
        "            c=dct(20*np.log10(c))\n",
        "            feat.append(c[:13])\n",
        "        mfcc13 = np.array(feat)\n",
        "        mfcc39 = np.zeros((mfcc13.shape[0], 39))\n",
        "        mfcc39[:,:13] = mfcc13\n",
        "        mfcc39[:,13:26] = mfcc13\n",
        "        mfcc39[:,26:39] = mfcc13\n",
        "        for l in range(1,12):\n",
        "            mfcc39[:,13+l] = (mfcc13[:,l+1] - mfcc13[:,l-1])/2.0\n",
        "        for l in range(2,11):\n",
        "            mfcc39[:,26+l] = (mfcc13[:,l+2] - mfcc13[:,l-2])/2.0\n",
        "        trainncodebook[i,j*60:(j+1)*60,:] = mfcc39\n",
        "        j=j+1\n",
        "    i=i+1\n",
        "    print('extractedtrainingfeatureforlabel', i)\n",
        "np.save('ncodebook',trainncodebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806d828e-a3d4-4575-b6c5-16f6d510369a",
      "metadata": {
        "id": "806d828e-a3d4-4575-b6c5-16f6d510369a",
        "outputId": "eb31dea0-a566-485f-c0c8-6b5aa075cf08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "traininglabel 0\n",
            "traininglabel 1\n",
            "traininglabel 2\n",
            "traininglabel 3\n",
            "traininglabel 4\n",
            "traininglabel 5\n",
            "traininglabel 6\n",
            "traininglabel 7\n",
            "traininglabel 8\n",
            "traininglabel 9\n"
          ]
        }
      ],
      "source": [
        "nvqcodebook4=np.zeros((10,4,39))\n",
        "for i in range(10):\n",
        "    nvqcodebook4[i] = kmeans(trainncodebook[i],4)[0]\n",
        "    print('traininglabel',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19c1ca0-5f3c-4ba0-9467-37ee895c1f14",
      "metadata": {
        "id": "a19c1ca0-5f3c-4ba0-9467-37ee895c1f14",
        "outputId": "aab031b4-a787-4ca4-d46e-ecc37f736aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "traininglabel 0\n",
            "traininglabel 1\n",
            "traininglabel 2\n",
            "traininglabel 3\n",
            "traininglabel 4\n",
            "traininglabel 5\n",
            "traininglabel 6\n",
            "traininglabel 7\n",
            "traininglabel 8\n",
            "traininglabel 9\n"
          ]
        }
      ],
      "source": [
        "nvqcodebook8=np.zeros((10,8,39))\n",
        "for i in range(10):\n",
        "    nvqcodebook8[i] = kmeans(trainncodebook[i],8)[0]\n",
        "    print('traininglabel',i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa20974-5312-4e4f-9aa8-e33593fdfc8c",
      "metadata": {
        "id": "6fa20974-5312-4e4f-9aa8-e33593fdfc8c"
      },
      "source": [
        "TESTING on noisy test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf042af2-1ec9-4bca-a05c-8ad8422ec658",
      "metadata": {
        "id": "cf042af2-1ec9-4bca-a05c-8ad8422ec658",
        "outputId": "394b53be-9e42-4505-bc7b-47e08b11bea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing on label 0\n",
            "testing on label 1\n",
            "testing on label 2\n",
            "testing on label 3\n",
            "testing on label 4\n",
            "testing on label 5\n",
            "testing on label 6\n",
            "testing on label 7\n",
            "testing on label 8\n",
            "testing on label 9\n",
            "Accuracy= 20.166666666666668\n",
            "[[ 26   5   4  55   4   1   3  10 127   5]\n",
            " [ 19  71   6  26   4   7   7   8  83   9]\n",
            " [ 16   6  30  38   4  14  13   6  96  17]\n",
            " [ 14   6   3  42   3   4  10  10 145   3]\n",
            " [  5  11   4  68  15   6  17   7  96  11]\n",
            " [ 11  13  16   9   1  25  11  26 106  22]\n",
            " [ 30  29  12  37   4  12  30  13  70   3]\n",
            " [  4   7   1   1   0   4   1  42 165  15]\n",
            " [  2   2   2   5   0   7   2  17 188  15]\n",
            " [  3   4   6   3   1   4   0  20 184  15]]\n"
          ]
        }
      ],
      "source": [
        "pred= []\n",
        "gt= []\n",
        "for i in range(10):\n",
        "    for j in range(240):\n",
        "        feat = testncodebook[i, 60*j:60*(j+1),:]\n",
        "        labeldist=[]\n",
        "        for label in range(10):\n",
        "            sumdist=0\n",
        "            for l in range (60):\n",
        "                dists=[]\n",
        "                for k in range(4):\n",
        "                    dist=0.0\n",
        "                    for m in range(39):\n",
        "                        dist=dist+ (feat[l][m]-nvqcodebook4[label,k][m])**2\n",
        "                    dists.append(dist)\n",
        "                sumdist= sumdist+  min(dists)\n",
        "            labeldist.append(sumdist)\n",
        "        prediction=np.argmin(labeldist)\n",
        "        pred.append(prediction)\n",
        "        gt.append(i)\n",
        "    print('testing on label',i)\n",
        "true=0\n",
        "for q in range (len(gt)):\n",
        "    if (gt[q]==pred[q]):\n",
        "        true=true+1\n",
        "print(\"Accuracy=\",true*100/len(gt))\n",
        "print(confusion_matrix(gt, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0706a9e8-2d1f-4c42-acb9-056092096576",
      "metadata": {
        "id": "0706a9e8-2d1f-4c42-acb9-056092096576",
        "outputId": "6cb79928-34c7-427c-84d3-d34fad6c7fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing on label 0\n",
            "testing on label 1\n",
            "testing on label 2\n",
            "testing on label 3\n",
            "testing on label 4\n",
            "testing on label 5\n",
            "testing on label 6\n",
            "testing on label 7\n",
            "testing on label 8\n",
            "testing on label 9\n",
            "Accuracy= 23.875\n",
            "[[ 67   2   5  41  13   0   1  10 100   1]\n",
            " [ 21  77   8  20  11   0   7  13  71  12]\n",
            " [ 21   7  24  26   9  10   6  11 108  18]\n",
            " [ 31   3   4  50   2   1   4  10 132   3]\n",
            " [ 40   5   4  53  26   2   5   7  90   8]\n",
            " [  6  14  12   5   4  19  11  43 100  26]\n",
            " [ 42  23   8  25  13   3  18  13  86   9]\n",
            " [  1   3   2   4   0   3   1  81 131  14]\n",
            " [  2   1   4   8   1   1   1  18 189  15]\n",
            " [  1   0   3  13   2   1   0  25 173  22]]\n"
          ]
        }
      ],
      "source": [
        "pred= []\n",
        "gt= []\n",
        "for i in range(10):\n",
        "    for j in range(240):\n",
        "        feat = testncodebook[i, 60*j:60*(j+1),:]\n",
        "        labeldist=[]\n",
        "        for label in range(10):\n",
        "            sumdist=0\n",
        "            for l in range (60):\n",
        "                dists=[]\n",
        "                for k in range(8):\n",
        "                    dist=0.0\n",
        "                    for m in range(39):\n",
        "                        dist=dist+ (feat[l][m]-nvqcodebook8[label,k][m])**2\n",
        "                    dists.append(dist)\n",
        "                sumdist= sumdist+  min(dists)\n",
        "            labeldist.append(sumdist)\n",
        "        prediction=np.argmin(labeldist)\n",
        "        pred.append(prediction)\n",
        "        gt.append(i)\n",
        "    print('testing on label',i)\n",
        "true=0\n",
        "for q in range (len(gt)):\n",
        "    if (gt[q]==pred[q]):\n",
        "        true=true+1\n",
        "print(\"Accuracy=\",true*100/len(gt))\n",
        "print(confusion_matrix(gt, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d5debb-0bf8-421b-ba18-5358b3956c73",
      "metadata": {
        "id": "a5d5debb-0bf8-421b-ba18-5358b3956c73"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}